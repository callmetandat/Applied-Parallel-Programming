{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Compute Capability: (8, 9)\n",
      "Total Memory: 8.00 GB\n",
      "Multiprocessor Count: 24\n",
      "Max Threads per Block: 1024\n",
      "Max Block Dimensions: 1024, 1024, 64\n",
      "Max Grid Dimensions: 2147483647, 65535, 65535\n",
      "Warp Size: 32\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "\n",
    "\n",
    "device = cuda.get_current_device()\n",
    "\n",
    "\n",
    "print(f\"GPU Name: {device.name.decode('utf-8')}\")\n",
    "print(f\"Compute Capability: {device.compute_capability}\")\n",
    "\n",
    "\n",
    "mem_info = cuda.current_context().get_memory_info()\n",
    "total_memory = mem_info[1]  \n",
    "print(f\"Total Memory: {total_memory / (1024**3):.2f} GB\")\n",
    "\n",
    "print(f\"Multiprocessor Count: {device.MULTIPROCESSOR_COUNT}\")\n",
    "print(f\"Max Threads per Block: {device.MAX_THREADS_PER_BLOCK}\")\n",
    "print(f\"Max Block Dimensions: {device.MAX_BLOCK_DIM_X}, {device.MAX_BLOCK_DIM_Y}, {device.MAX_BLOCK_DIM_Z}\")\n",
    "print(f\"Max Grid Dimensions: {device.MAX_GRID_DIM_X}, {device.MAX_GRID_DIM_Y}, {device.MAX_GRID_DIM_Z}\")\n",
    "print(f\"Warp Size: {device.WARP_SIZE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Parallel**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution\n",
    "### Idea\n",
    "- The idea is to distribute the convolution operator of each output pixel across multiple threads.\n",
    "### Design\n",
    "- **Block Configuration (2D block)**: Each block has a size of 16x16 threads, covering a 16x16 region of the output image.\n",
    "- **Grid Configuration (3D grid)**:  The grid spans the entire output image dimensions (X and Y) and handles batch and output channels along the Z dimension. \n",
    "- **Thread Operations**: Each thread computes the value of one output pixel. It loops over all input channels, performing the convolution operation by multiplying input pixel values by corresponding kernel weights and accumulating the result. Then, the computed value is written to the corresponding position in the output feature map.\n",
    "### Implement\n",
    "\n",
    "<style>\n",
    "  .pseudo-code {\n",
    "    background-color: #e0e0e0;\n",
    "    color: #333;\n",
    "    border: 1px solid #ddd;\n",
    "    padding: 10px;\n",
    "    border-radius: 5px;\n",
    "    font-family: 'Courier New', Courier, monospace;\n",
    "    font-size: 18px;\n",
    "  }\n",
    "  .pseudo-code ul {\n",
    "    margin: 0;\n",
    "    padding-left: 20px;\n",
    "  }\n",
    "  .pseudo-code li {\n",
    "    margin-bottom: 5px;\n",
    "  }\n",
    "  .pseudo-code strong {\n",
    "    color: #007BFF;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<div class=\"pseudo-code\">\n",
    "  <strong>directConv2D_kernel</strong>:\n",
    "  <ul>\n",
    "    <li><strong>Inputs</strong>:\n",
    "      <ul>\n",
    "        <li>img, output, weight, bias, in_channel, out_channel, batch_size</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "    <li>Calculate out_row, out_col, z_idx using a 3D CUDA grid.</li>\n",
    "    <li>Determine batch_idx by integer division of z_idx by out_channel.</li>\n",
    "    <li>Determine out_channel_idx by computing the remainder of z_idx divided by out_channel.</li>\n",
    "    <li><strong>If</strong> out_row and out_col are within the output image bounds:\n",
    "      <ul>\n",
    "        <li>Initialize outPixel with the bias for the current output channel.</li>\n",
    "        <li><strong>For each</strong> input channel index:\n",
    "          <ul>\n",
    "            <li><strong>For each</strong> kernel row:\n",
    "              <ul>\n",
    "                <li><strong>For each</strong> kernel column:\n",
    "                  <ul>\n",
    "                    <li>Multiply the corresponding weight and image pixel, add to outPixel.</li>\n",
    "                  </ul>\n",
    "                </li>\n",
    "              </ul>\n",
    "            </li>\n",
    "          </ul>\n",
    "        </li>\n",
    "        <li>Store the computed outPixel in the output image.</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "  </ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer (channel in * channel_out)</th>\n",
       "      <th>Sequential (s)</th>\n",
       "      <th>Numba Runtime (s)</th>\n",
       "      <th>Different (mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3, 64)</td>\n",
       "      <td>231.343723</td>\n",
       "      <td>1.070358</td>\n",
       "      <td>4.478326e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(64, 128)</td>\n",
       "      <td>149.354147</td>\n",
       "      <td>0.801589</td>\n",
       "      <td>4.130972e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(128, 256)</td>\n",
       "      <td>89.949023</td>\n",
       "      <td>0.788387</td>\n",
       "      <td>1.154061e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(256, 512)</td>\n",
       "      <td>59.084347</td>\n",
       "      <td>0.784225</td>\n",
       "      <td>3.211508e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(512, 1024)</td>\n",
       "      <td>44.752300</td>\n",
       "      <td>0.776366</td>\n",
       "      <td>8.802213e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Layer (channel in * channel_out)  Sequential (s)  Numba Runtime (s)  \\\n",
       "0                          (3, 64)      231.343723           1.070358   \n",
       "1                        (64, 128)      149.354147           0.801589   \n",
       "2                       (128, 256)       89.949023           0.788387   \n",
       "3                       (256, 512)       59.084347           0.784225   \n",
       "4                      (512, 1024)       44.752300           0.776366   \n",
       "\n",
       "   Different (mean)  \n",
       "0      4.478326e-07  \n",
       "1      4.130972e-05  \n",
       "2      1.154061e-04  \n",
       "3      3.211508e-04  \n",
       "4      8.802213e-04  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "from pandas import DataFrame\n",
    "from time import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from model_numba.layers_cpu.layer import ConvolutionalLayer\n",
    "from model_numba.Layers.Layers import DirectConv2DGPU\n",
    "import pandas as pd  \n",
    "\n",
    "\n",
    "columns = [\"Layer (channel in * channel_out)\", \"Sequential (s)\", \"Numba Runtime (s)\", \"Different (mean)\"]\n",
    "df = DataFrame(columns=columns)\n",
    "\n",
    "def compare(in_channel, out_channel, img_size):\n",
    "    global df  \n",
    "    \n",
    "    img = torch.rand(size=(4, in_channel, img_size, img_size), dtype=torch.float32)\n",
    "    weight = torch.rand(size=(out_channel, in_channel, 3, 3), dtype=torch.float32)\n",
    "    bias = torch.rand(size=(out_channel,), dtype=torch.float32)\n",
    "\n",
    "    # CPU computation\n",
    "    cpu_conv = ConvolutionalLayer(in_channel, out_channel, 3, 1, 1, weight.numpy(), bias.numpy())\n",
    "    start = time()\n",
    "    cpu_output = cpu_conv.forward(img.numpy())\n",
    "    end = time()\n",
    "    cpu_runtime = end - start\n",
    "\n",
    "  \n",
    "    start = time()\n",
    "    numba_output = DirectConv2DGPU(img.numpy(), weight.numpy(), bias.numpy(), True)\n",
    "    end = time()\n",
    "    gpu_runtime = end - start\n",
    "\n",
    "\n",
    "    ret = {\n",
    "        \"Layer (channel in * channel_out)\": (in_channel, out_channel),\n",
    "        \"Sequential (s)\": cpu_runtime,\n",
    "        \"Numba Runtime (s)\": gpu_runtime,\n",
    "        \"Different (mean)\": np.mean(np.abs(numba_output - cpu_output))\n",
    "    }\n",
    "\n",
    " \n",
    "    new_row_df = DataFrame([ret], columns=df.columns)\n",
    "    df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "compare(3, 64, 512)\n",
    "compare(64, 128, 256)\n",
    "compare(128, 256, 128)\n",
    "compare(256, 512, 64)\n",
    "compare(512, 1024, 32)\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Idea\n",
    "- Each pixel is normalized independently. Therefore, dividing each pixel per thread speeds up compution.\n",
    "### Design\n",
    "- **Block Configuration (1D block)**: Each block has a size of 256 threads.\n",
    "- **Grid Configuration (3D grid)**:  The X axis handles whole dimensions of output image and channel, Z handles batch.\n",
    "- **Thread Operations**: Each thread noramlizes the value of one input pixel and write it to the corresponding pixel. \n",
    "### Implement\n",
    "<style>\n",
    "  .pseudo-code {\n",
    "    background-color: #e0e0e0; /* Light gray background */\n",
    "    color: #333; /* Dark gray text */\n",
    "    border: 1px solid #bbb; /* Gray border */\n",
    "    padding: 10px;\n",
    "    border-radius: 5px;\n",
    "    font-family: 'Courier New', Courier, monospace;\n",
    "    font-size: 18px;\n",
    "  }\n",
    "  .pseudo-code ul {\n",
    "    margin: 0;\n",
    "    padding-left: 20px;\n",
    "  }\n",
    "  .pseudo-code li {\n",
    "    margin-bottom: 5px;\n",
    "  }\n",
    "  .pseudo-code strong {\n",
    "    color: #007BFF; /* Blue color for strong text */\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<div class=\"pseudo-code\">\n",
    "  <strong>batchNorm2D_kernel</strong>:\n",
    "  <ul>\n",
    "    <li><strong>Inputs</strong>:\n",
    "      <ul>\n",
    "        <li>img, out_img, batchNorm_weight, batchNorm_bias, mean, variance, epsilon</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "    <li>Calculate out_x, out_y using a 2D CUDA grid.</li>\n",
    "    <li>Determine in channel index.</li>\n",
    "    <li>Determine batch index.</li>\n",
    "    <li><strong>Check for valid pixel index</strong> \n",
    "      <ul>\n",
    "        <li>Calculate normalized value of input pixel.</li>\n",
    "        <li>Store the computed value in corresponding output pixel.</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "  </ul>\n",
    "</div>\n",
    "\n",
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Size (C, H, W)</th>\n",
       "      <th>Sequential (s)</th>\n",
       "      <th>Numba Runtime (s)</th>\n",
       "      <th>Different (mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(64, 512, 512)</td>\n",
       "      <td>123.179057</td>\n",
       "      <td>0.430730</td>\n",
       "      <td>5.728351e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(128, 256, 256)</td>\n",
       "      <td>60.489841</td>\n",
       "      <td>0.286713</td>\n",
       "      <td>8.855715e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(256, 128, 128)</td>\n",
       "      <td>30.162915</td>\n",
       "      <td>0.178511</td>\n",
       "      <td>7.653616e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(512, 64, 64)</td>\n",
       "      <td>15.143800</td>\n",
       "      <td>0.087400</td>\n",
       "      <td>6.969669e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Input Size (C, H, W)  Sequential (s)  Numba Runtime (s)  Different (mean)\n",
       "0       (64, 512, 512)      123.179057           0.430730      5.728351e-09\n",
       "1      (128, 256, 256)       60.489841           0.286713      8.855715e-09\n",
       "2      (256, 128, 128)       30.162915           0.178511      7.653616e-09\n",
       "3        (512, 64, 64)       15.143800           0.087400      6.969669e-09"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "from pandas import DataFrame\n",
    "from time import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from model_numba.layers_cpu.layer import BatchNorm2D_CPU\n",
    "from model_numba.Layers.Layers import batchNorm2D\n",
    "import pandas as pd  \n",
    "\n",
    "\n",
    "columns = [\"Input Size (C, H, W)\", \"Sequential (s)\", \"Numba Runtime (s)\", \"Different (mean)\"]\n",
    "df = DataFrame(columns=columns)\n",
    "\n",
    "def compare(in_channel, img_size):\n",
    "    global df  \n",
    "    \n",
    "    img = torch.rand(size=(4, in_channel, img_size, img_size), dtype=torch.float32)\n",
    "    weight = torch.rand(size=(in_channel,), dtype=torch.float32)\n",
    "    bias = torch.rand(size=(in_channel,), dtype=torch.float32)\n",
    "    mean = torch.rand(size=(in_channel,), dtype=torch.float32)\n",
    "    var = torch.rand(size=(in_channel,), dtype=torch.float32)\n",
    "\n",
    "    # CPU computation\n",
    "    cpu_batchnorm = BatchNorm2D_CPU(in_channel, weight.numpy(), bias.numpy())\n",
    "    start = time()\n",
    "    cpu_output = cpu_batchnorm.forward(img.numpy(), mean.numpy(), var.numpy())\n",
    "    end = time()\n",
    "    cpu_runtime = end - start\n",
    "\n",
    "  \n",
    "    start = time()\n",
    "    numba_output = batchNorm2D(img.numpy(), weight.numpy(), bias.numpy(),mean.numpy(), var.numpy())\n",
    "    end = time()\n",
    "    gpu_runtime = end - start\n",
    "\n",
    "\n",
    "    ret = {\n",
    "        \"Input Size (C, H, W)\": (in_channel, img_size, img_size),\n",
    "        \"Sequential (s)\": cpu_runtime,\n",
    "        \"Numba Runtime (s)\": gpu_runtime,\n",
    "        \"Different (mean)\": np.mean(np.abs(numba_output - cpu_output))\n",
    "    }\n",
    "\n",
    " \n",
    "    new_row_df = DataFrame([ret], columns=df.columns)\n",
    "    df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "compare( 64, 512)\n",
    "compare(128, 256)\n",
    "compare(256, 128)\n",
    "compare(512, 64)\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLu Activation\n",
    "### Idea\n",
    "- ReLu Activation applies single element-wise operator: $ ReLU(x)=max(0,x) $ for each input pixels. So, we can compute this operator accoss multiple threads to improve performance.\n",
    "### Desgin\n",
    "- **Block Configuration (1D block)**: Each block has a size of 256 threads.\n",
    "- **Grid Configuration (3D grid)**:  The X axis handles whole dimensions of output image and channels, Z handles batch.\n",
    "- **Thread Operations**: Each thread applies the ReLU function to one input pixel and write it to the corresponding pixel.\n",
    "### Implement\n",
    "<style>\n",
    "  .pseudo-code {\n",
    "    background-color: #e0e0e0; /* Light gray background */\n",
    "    color: #333; /* Dark gray text */\n",
    "    border: 1px solid #bbb; /* Gray border */\n",
    "    padding: 10px;\n",
    "    border-radius: 5px;\n",
    "    font-family: 'Courier New', Courier, monospace;\n",
    "    font-size: 16px; /* Larger text size */\n",
    "  }\n",
    "  .pseudo-code ul {\n",
    "    margin: 0;\n",
    "    padding-left: 20px;\n",
    "  }\n",
    "  .pseudo-code li {\n",
    "    margin-bottom: 5px;\n",
    "  }\n",
    "  .pseudo-code strong {\n",
    "    color: #007BFF; /* Blue color for strong text */\n",
    "    font-size: 18px; /* Larger size for strong text */\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<div class=\"pseudo-code\">\n",
    "  <strong>relu_kernel</strong>:\n",
    "  <ul>\n",
    "    <li><strong>Inputs</strong>:\n",
    "      <ul>\n",
    "        <li>data, batch size, number of channels, img width, imgheight</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "    <li>Calculate <strong>idx</strong> using a 1D CUDA grid.</li>\n",
    "    <li>Determine the total number of elements as <strong>batch_size * channels * img_width * img_height</strong>.</li>\n",
    "    <li><strong>If</strong> <em>idx</em> is within the range of total elements:\n",
    "      <ul>\n",
    "        <li>Calculate <strong>b</strong> as the integer division of <em>idx</em> by <em>(channels * img_width * img_height)</em>.</li>\n",
    "        <li>Calculate <strong>c</strong> as the modulo of <em>idx</em> by <em>(channels * img_width * img_height)</em>, then integer division by <em>(img_width * img_height)</em>.</li>\n",
    "        <li>Calculate <strong>w</strong> as the modulo of <em>idx</em> by <em>(img_width * img_height)</em>, then integer division by <em>img_height</em>.</li>\n",
    "        <li>Calculate <strong>h</strong> as <em>idx</em> modulo <em>img_height</em>.</li>\n",
    "        <li>Update <strong>data[b, c, w, h]</strong> to be the maximum of its current value and 0.</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "  </ul>\n",
    "</div>\n",
    "\n",
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Size (C, H, W)</th>\n",
       "      <th>Sequential (s)</th>\n",
       "      <th>Numba Runtime (s)</th>\n",
       "      <th>Different (mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(64, 512, 512)</td>\n",
       "      <td>81.952738</td>\n",
       "      <td>0.293049</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(128, 256, 256)</td>\n",
       "      <td>41.761168</td>\n",
       "      <td>0.210163</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(256, 128, 128)</td>\n",
       "      <td>20.765348</td>\n",
       "      <td>0.106927</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(512, 64, 64)</td>\n",
       "      <td>10.411028</td>\n",
       "      <td>0.055011</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Input Size (C, H, W)  Sequential (s)  Numba Runtime (s)  Different (mean)\n",
       "0       (64, 512, 512)       81.952738           0.293049               0.0\n",
       "1      (128, 256, 256)       41.761168           0.210163               0.0\n",
       "2      (256, 128, 128)       20.765348           0.106927               0.0\n",
       "3        (512, 64, 64)       10.411028           0.055011               0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "from pandas import DataFrame\n",
    "from time import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from model_numba.layers_cpu.layer import ReLU_CPU\n",
    "from model_numba.Layers.Layers import RELU_GPU\n",
    "import pandas as pd  \n",
    "\n",
    "\n",
    "columns = [\"Input Size (C, H, W)\", \"Sequential (s)\", \"Numba Runtime (s)\", \"Different (mean)\"]\n",
    "df = DataFrame(columns=columns)\n",
    "\n",
    "def compare(in_channel, img_size):\n",
    "    global df  \n",
    "    \n",
    "    img = torch.rand(size=(4, in_channel, img_size, img_size), dtype=torch.float32)\n",
    "\n",
    "\n",
    "    # CPU computation\n",
    "    cpu_batchnorm = ReLU_CPU()\n",
    "    start = time()\n",
    "    cpu_output = cpu_batchnorm.forward(img.numpy())\n",
    "    end = time()\n",
    "    cpu_runtime = end - start\n",
    "\n",
    "  \n",
    "    start = time()\n",
    "    numba_output = RELU_GPU(img.numpy())\n",
    "    end = time()\n",
    "    gpu_runtime = end - start\n",
    "\n",
    "\n",
    "    ret = {\n",
    "        \"Input Size (C, H, W)\": (in_channel, img_size, img_size),\n",
    "        \"Sequential (s)\": cpu_runtime,\n",
    "        \"Numba Runtime (s)\": gpu_runtime,\n",
    "        \"Different (mean)\": np.mean(np.abs(numba_output - cpu_output))\n",
    "    }\n",
    "\n",
    " \n",
    "    new_row_df = DataFrame([ret], columns=df.columns)\n",
    "    df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "compare( 64, 512)\n",
    "compare(128, 256)\n",
    "compare(256, 128)\n",
    "compare(512, 64)\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max Pooling 2D\n",
    "### Idea\n",
    "- Each output pixel is computed independently. Therefore, we can compute efficiently by parallelizing this layer on GPU.\n",
    "### Desgin\n",
    "- **Block Configuration (1D block)**: Each block has a size of 256 threads.\n",
    "- **Grid Configuration (3D grid)**:  The X axis handles whole dimensions of output image and channels, Z handles batch.\n",
    "- **Thread Operations**: Each thread compute four max operatiors of input pixels and write it to the corresponding pixel.\n",
    "### Implement\n",
    "<style>\n",
    "  .pseudo-code {\n",
    "    background-color: #e0e0e0; /* Light gray background */\n",
    "    color: #333; /* Dark gray text */\n",
    "    border: 1px solid #bbb; /* Gray border */\n",
    "    padding: 10px;\n",
    "    border-radius: 5px;\n",
    "    font-family: 'Courier New', Courier, monospace;\n",
    "    font-size: 18px; /* Larger text size */\n",
    "  }\n",
    "  .pseudo-code ul {\n",
    "    margin: 0;\n",
    "    padding-left: 20px;\n",
    "  }\n",
    "  .pseudo-code li {\n",
    "    margin-bottom: 5px;\n",
    "  }\n",
    "  .pseudo-code strong {\n",
    "    color: #007BFF; /* Blue color for strong text */\n",
    "    font-size: 18px; /* Larger size for strong text */\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<div class=\"pseudo-code\">\n",
    "  <strong>MaxPooling_Kernel</strong>:\n",
    "  <ul>\n",
    "    <li><strong>Inputs:</strong>\n",
    "      <ul>\n",
    "        <li>input, output, number of channels, output height, output width</li>\n",
    "      </ul>\n",
    "    </li>\n",
    "    <li>Calculate <strong>index</strong> using a 1D CUDA grid.</li>\n",
    "    <li>Determine the total number of output elements using <strong>output.size</strong>.</li>\n",
    "    <li><strong>If</strong> <em>index</em> is within the range of total output elements:\n",
    "      <ul>\n",
    "        <li>Calculate <strong>batch index</strong>, <strong>channel index</strong>, <strong>input pixel index</strong> and <strong>output pixel index</strong>.</li>\n",
    "        <li>Initialize <strong>max_val</strong> with the value at <em>input[batch index, channel index, input_row, input_col]</em>.</li>\n",
    "        <li>Update <strong>max_val</strong> by comparing it with adjacent values:\n",
    "          <ul>\n",
    "            <li>Check <em>input[batch index, channel index, input_row, input_col + 1]</em>.</li>\n",
    "            <li>Check <em>input[batch index, channel index, input_row + 1, input_col]</em>.</li>\n",
    "            <li>Check <em>input[batch index, channel index, input_row + 1, input_col + 1]</em>.</li>\n",
    "          </ul>\n",
    "        </li>\n",
    "      </ul>\n",
    "    </li>\n",
    "  </ul>\n",
    "</div>\n",
    "\n",
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Size (C, H, W)</th>\n",
       "      <th>Sequential (s)</th>\n",
       "      <th>Numba Runtime (s)</th>\n",
       "      <th>Different (mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(64, 512, 512)</td>\n",
       "      <td>33.361417</td>\n",
       "      <td>0.334031</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(128, 256, 256)</td>\n",
       "      <td>16.205704</td>\n",
       "      <td>0.143854</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(256, 128, 128)</td>\n",
       "      <td>8.189884</td>\n",
       "      <td>0.075449</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(512, 64, 64)</td>\n",
       "      <td>4.148149</td>\n",
       "      <td>0.046569</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Input Size (C, H, W)  Sequential (s)  Numba Runtime (s)  Different (mean)\n",
       "0       (64, 512, 512)       33.361417           0.334031               0.0\n",
       "1      (128, 256, 256)       16.205704           0.143854               0.0\n",
       "2      (256, 128, 128)        8.189884           0.075449               0.0\n",
       "3        (512, 64, 64)        4.148149           0.046569               0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "from pandas import DataFrame\n",
    "from time import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from model_numba.layers_cpu.layer import MaxPooling2D_CPU\n",
    "from model_numba.Layers.Layers import MaxPooling2D_GPU\n",
    "import pandas as pd  \n",
    "\n",
    "\n",
    "columns = [\"Input Size (C, H, W)\", \"Sequential (s)\", \"Numba Runtime (s)\", \"Different (mean)\"]\n",
    "df = DataFrame(columns=columns)\n",
    "\n",
    "def compare(in_channel, img_size):\n",
    "    global df  \n",
    "    \n",
    "    img = torch.rand(size=(4, in_channel, img_size, img_size), dtype=torch.float32)\n",
    "\n",
    "\n",
    "    # CPU computation\n",
    "    cpu_batchnorm = MaxPooling2D_CPU()\n",
    "    start = time()\n",
    "    cpu_output = cpu_batchnorm.forward(img.numpy())\n",
    "    end = time()\n",
    "    cpu_runtime = end - start\n",
    "\n",
    "  \n",
    "    start = time()\n",
    "    numba_output = MaxPooling2D_GPU(img.numpy(),True)\n",
    "    end = time()\n",
    "    gpu_runtime = end - start\n",
    "\n",
    "\n",
    "    ret = {\n",
    "        \"Input Size (C, H, W)\": (in_channel, img_size, img_size),\n",
    "        \"Sequential (s)\": cpu_runtime,\n",
    "        \"Numba Runtime (s)\": gpu_runtime,\n",
    "        \"Different (mean)\": np.mean(np.abs(numba_output - cpu_output))\n",
    "    }\n",
    "\n",
    " \n",
    "    new_row_df = DataFrame([ret], columns=df.columns)\n",
    "    df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "compare( 64, 512)\n",
    "compare(128, 256)\n",
    "compare(256, 128)\n",
    "compare(512, 64)\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Optimized**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 1: Optimized Convolution layers using Shared Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea\n",
    "- The goal of this version is to optimize the convolution operation by utilizing the shared memory of the GPU, which is much faster than global memory. By dividing the image into smaller tiles and loading them into shared memory, we can reduce the number of redundant global memory accesses, resulting in a significant performance boost.\n",
    "#### Design\n",
    "- **2D Blocks**: Each block processes a tile of the input image. The block size is 16x16.\n",
    "- **3D Grid**: X and Y dimensions Handle the spatial dimensions of the image (width and height) and Z dimension Handles the batch and output channels, allowing for parallel processing across different images and feature maps.  \n",
    "![alt text](tile.png)  \n",
    "\n",
    "In the image above, we utilize two tiles: the input tile and the output tile. The input tile serves to copy each input pixel to a shared array, while the output tile is responsible for computing the convolution of each output pixel within its bounds.  To prevent data loss at tile boundaries, we employ a specific formula for calculating thread indices:  \n",
    "\n",
    "Column index for output:  \n",
    "-   $col_{out} = cuda.blockIdx.x * OUTPUT TILE SIZE + threadIdx.x$  \n",
    "    \n",
    "\n",
    "Row index for output:  \n",
    "-   $row_{out} = cuda.blockIdx.y * OUTPUT TILE SIZE + threadIdx.y$  \n",
    "\n",
    "This approach facilitates the overlap between neighboring input tiles.\n",
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer (channel in * channel_out)</th>\n",
       "      <th>Direct Conv (s)</th>\n",
       "      <th>TileShared Conv (s)</th>\n",
       "      <th>Different (mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3, 64)</td>\n",
       "      <td>0.708337</td>\n",
       "      <td>0.452569</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(64, 128)</td>\n",
       "      <td>0.525432</td>\n",
       "      <td>0.308580</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(128, 256)</td>\n",
       "      <td>0.492068</td>\n",
       "      <td>0.292706</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(256, 512)</td>\n",
       "      <td>0.481996</td>\n",
       "      <td>0.283913</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(512, 1024)</td>\n",
       "      <td>0.485973</td>\n",
       "      <td>0.323966</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Layer (channel in * channel_out)  Direct Conv (s)  TileShared Conv (s)  \\\n",
       "0                          (3, 64)         0.708337             0.452569   \n",
       "1                        (64, 128)         0.525432             0.308580   \n",
       "2                       (128, 256)         0.492068             0.292706   \n",
       "3                       (256, 512)         0.481996             0.283913   \n",
       "4                      (512, 1024)         0.485973             0.323966   \n",
       "\n",
       "   Different (mean)  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "from pandas import DataFrame\n",
    "from time import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from model_numba.Layers.Layers import DirectConv2DGPU, Convolution2D_GPU\n",
    "import pandas as pd  \n",
    "\n",
    "\n",
    "columns = [\"Layer (channel in * channel_out)\",\"Direct Conv (s)\", \"TileShared Conv (s)\", \"Different (mean)\"]\n",
    "df = DataFrame(columns=columns)\n",
    "\n",
    "def compare(in_channel, out_channel, img_size):\n",
    "    global df  \n",
    "    \n",
    "    img = torch.rand(size=(4, in_channel, img_size, img_size), dtype=torch.float32)\n",
    "    weight = torch.rand(size=(out_channel, in_channel, 3, 3), dtype=torch.float32)\n",
    "    bias = torch.rand(size=(out_channel,), dtype=torch.float32)\n",
    "    \n",
    "\n",
    "    # CPU computation\n",
    "    start = time()\n",
    "    numba_output_1 = DirectConv2DGPU(img.numpy(), weight.numpy(), bias.numpy(), True)\n",
    "    end = time()\n",
    "    direct = end - start\n",
    "\n",
    "  \n",
    "    start = time()\n",
    "    numba_output_2 = Convolution2D_GPU(img.numpy(), weight.numpy(), bias.numpy(), True)\n",
    "    end = time()\n",
    "    tile = end - start\n",
    "\n",
    "\n",
    "    ret = {\n",
    "        \"Layer (channel in * channel_out)\": (in_channel, out_channel),\n",
    "        \"Direct Conv (s)\": direct,\n",
    "        \"TileShared Conv (s)\": tile,\n",
    "        \"Different (mean)\": np.mean(np.abs(numba_output_1 - numba_output_2))\n",
    "    }\n",
    "\n",
    " \n",
    "    new_row_df = DataFrame([ret], columns=df.columns)\n",
    "    df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "compare(3, 64, 512)\n",
    "compare(64, 128, 256)\n",
    "compare(128, 256, 128)\n",
    "compare(256, 512, 64)\n",
    "compare(512, 1024, 32)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2: Combie Convolution, ReLu and BatchNorm2D into single kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-Combine convolution\n",
    "![](original_conv.png)  \n",
    "#### Combine convolution\n",
    "![alt text](optimized_conv.png)\n",
    "\n",
    "- In the non-combined convolution implementation, there are six data transfers between the host and device. In the combined version, the tile-shared convolution kernel performs additional steps—normalization and ReLU activation—after the convolution operation. This approach reduces the number of data transfers to just two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer (channel in * channel_out)</th>\n",
       "      <th>Non-Combie Conv (s)</th>\n",
       "      <th>Combie Conv (s)</th>\n",
       "      <th>Different (mean)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(3, 64)</td>\n",
       "      <td>0.527608</td>\n",
       "      <td>0.279877</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(64, 128)</td>\n",
       "      <td>0.456157</td>\n",
       "      <td>0.106524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(128, 256)</td>\n",
       "      <td>0.358132</td>\n",
       "      <td>0.089497</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(256, 512)</td>\n",
       "      <td>0.318990</td>\n",
       "      <td>0.082366</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(512, 1024)</td>\n",
       "      <td>0.320638</td>\n",
       "      <td>0.105859</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Layer (channel in * channel_out)  Non-Combie Conv (s)  Combie Conv (s)  \\\n",
       "0                          (3, 64)             0.527608         0.279877   \n",
       "1                        (64, 128)             0.456157         0.106524   \n",
       "2                       (128, 256)             0.358132         0.089497   \n",
       "3                       (256, 512)             0.318990         0.082366   \n",
       "4                      (512, 1024)             0.320638         0.105859   \n",
       "\n",
       "   Different (mean)  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reset -f\n",
    "from pandas import DataFrame\n",
    "from time import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from model_numba.Layers.Layers import DirectConv2DGPU, Convolution2D_GPU,Combie_TileConv_GPU, RELU_GPU, batchNorm2D\n",
    "import pandas as pd  \n",
    "\n",
    "\n",
    "columns = [\"Layer (channel in * channel_out)\",\"Non-Combie Conv (s)\", \"Combie Conv (s)\", \"Different (mean)\"]\n",
    "df = DataFrame(columns=columns)\n",
    "\n",
    "def compare(in_channel, out_channel, img_size):\n",
    "    global df  \n",
    "    \n",
    "    img = torch.rand(size=(4, in_channel, img_size, img_size), dtype=torch.float32)\n",
    "    weight = torch.rand(size=(out_channel, in_channel, 3, 3), dtype=torch.float32)\n",
    "    bias = torch.rand(size=(out_channel,), dtype=torch.float32)\n",
    "    batch_weight = torch.rand(size=(in_channel,), dtype=torch.float32)\n",
    "    batch_bias = torch.rand(size=(in_channel,), dtype=torch.float32)\n",
    "    mean = torch.rand(size=(in_channel,), dtype=torch.float32)\n",
    "    var = torch.rand(size=(in_channel,), dtype=torch.float32)\n",
    "\n",
    "    # CPU computation\n",
    "    start = time()\n",
    "    numba_output_1 = Convolution2D_GPU(img.numpy(), weight.numpy(), bias.numpy(), True)\n",
    "    numba_output_1 = batchNorm2D(numba_output_1, batch_weight.numpy(), batch_bias.numpy(), mean.numpy(), var.numpy())\n",
    "    numba_output_1 = RELU_GPU(numba_output_1)\n",
    "    end = time()\n",
    "    direct = end - start\n",
    "\n",
    "  \n",
    "    start = time()\n",
    "    numba_output_2 = Combie_TileConv_GPU(img.numpy(), weight.numpy(), bias.numpy(),batch_weight.numpy(), batch_bias.numpy(), mean.numpy(), var.numpy(), True)\n",
    "    end = time()\n",
    "    tile = end - start\n",
    "\n",
    "\n",
    "    ret = {\n",
    "        \"Layer (channel in * channel_out)\": (in_channel, out_channel),\n",
    "        \"Non-Combie Conv (s)\": direct,\n",
    "        \"Combie Conv (s)\": tile,\n",
    "        \"Different (mean)\": np.mean(np.abs(numba_output_1 - numba_output_2))\n",
    "    }\n",
    "\n",
    " \n",
    "    new_row_df = DataFrame([ret], columns=df.columns)\n",
    "    df = pd.concat([df, new_row_df], ignore_index=True)\n",
    "\n",
    "\n",
    "compare(3, 64, 512)\n",
    "compare(64, 128, 256)\n",
    "compare(128, 256, 128)\n",
    "compare(256, 512, 64)\n",
    "compare(512, 1024, 32)\n",
    "\n",
    "# Display the DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 3: Reduce data transfer between layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In this version, the goal is to minimize data transfers as much as possible. We achieve this by reducing data transfers at various layers: double convolution, maxpooling-double convolution, and transpose convolution-double convolution. Data is only transferred at the first layer, the last layer, and occasionally at skip connection steps if CPU code is used for concatenation. The optimizations are illustrated below:\n",
    "\n",
    "- **Maxpooling-Double Convolution**  \n",
    "  ![alt text](optimize_maxpool.png)  \n",
    "  This optimization reduces data transfers from 4 to 0, which is the same for transpose convolution-double convolution.\n",
    "\n",
    "- **Double Convolution**  \n",
    "  *Original*  \n",
    "  ![alt text](original_combie_conv.png)  \n",
    "  *Optimized*  \n",
    "  ![alt text](optimize_combie_conv.png)  \n",
    "  This optimization reduces data transfers from 4 to 0 (or 1 if this double convolution is the first layer).\n",
    "\n",
    "### Table: Number of Data Transfers Per Block\n",
    "\n",
    "|        | **Original** | **Optimized** |\n",
    "|--------|--------------|---------------|\n",
    "| **down_1** | 12 transfers  | 1 transfer    |\n",
    "| **down_2** | 16 transfers  | 0 transfers   |\n",
    "| **down_3** | 16 transfers  | 0 transfers   |\n",
    "| **down_4** | 16 transfers  | 0 transfers   |\n",
    "| **down_5** | 16 transfers  | 0 transfers   |\n",
    "| **up_1**   | 16 transfers  | 1 transfer    |\n",
    "| **up_2**   | 16 transfers  | 1 transfer    |\n",
    "| **up_3**   | 16 transfers  | 1 transfer    |\n",
    "| **up_4**   | 16 transfers  | 1 transfer    |\n",
    "| **out**    | 2 transfers   | 1 transfer    |\n",
    "| **Total**  | 142 transfers | 6 transfers   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "-   We run the entire model using version 3 and compare it with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch CPU Runtime: 0.7206525802612305s\n",
      "Numba Runtime: 0.979292631149292s\n",
      "Mean Difference: 0.000504146097227931\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%reset -f\n",
    "from model_numba.unet_cuda import Unet_Cuda\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "image = Image.open('test.jpg')\n",
    "import numpy as np\n",
    "image = transform(image).unsqueeze(0)\n",
    "image.shape\n",
    "\n",
    "\n",
    "from model.unet import U_net\n",
    "model = U_net(1).eval()\n",
    "weight = torch.load('weights/weights.pth')\n",
    "model.load_state_dict(weight)\n",
    "\n",
    "numba_model = Unet_Cuda(1).eval()\n",
    "\n",
    "\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "out_pytorch = model(image)\n",
    "end = time()\n",
    "print(f'Pytorch CPU Runtime: {end-start}s')\n",
    "\n",
    "start = time()\n",
    "out_numba = numba_model(image.numpy())\n",
    "end = time()\n",
    "\n",
    "print(f'Numba Runtime: {end-start}s')\n",
    "\n",
    "print(f'Mean Difference: {np.mean(np.abs(out_pytorch.cpu().detach().numpy()- out_numba))}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
